{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия и стохастический градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание основано на материалах лекций по линейной регрессии и градиентному спуску. Вы будете прогнозировать выручку компании в зависимости от уровня ее инвестиций в рекламу по TV, в газетах и по радио."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вы научитесь:\n",
    "- решать задачу восстановления линейной регрессии\n",
    "- реализовывать стохастический градиентный спуск для ее настройки\n",
    "- решать задачу линейной регрессии аналитически"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Введение\n",
    "Линейная регрессия - один из наиболее хорошо изученных методов машинного обучения, позволяющий прогнозировать значения количественного признака в виде линейной комбинации прочих признаков с параметрами - весами модели. Оптимальные (в смысле минимальности некоторого функционала ошибки) параметры линейной регрессии можно найти аналитически с помощью нормального уравнения или численно с помощью методов оптимизации.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Линейная регрессия использует простой функционал качества - среднеквадратичную ошибку. Мы будем работать с выборкой, содержащей 3 признака. Для настройки параметров (весов) модели решается следующая задача:\n",
    "$$\\Large \\frac{1}{\\ell}\\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}^2} \\rightarrow \\min_{w_0, w_1, w_2, w_3},$$\n",
    "где $x_{i1}, x_{i2}, x_{i3}$ - значения признаков $i$-го объекта, $y_i$ - значение целевого признака $i$-го объекта, $\\ell$ - число объектов в обучающей выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Градиентный спуск\n",
    "Параметры $w_0, w_1, w_2, w_3$, по которым минимизируется среднеквадратичная ошибка, можно находить численно с помощью градиентного спуска.\n",
    "Градиентный шаг для весов будет выглядеть следующим образом:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} \\sum_{i=1}^\\ell{{x_{ij}((w_0 + w_1x_{i1} + w_2x_{i2} +  w_3x_{i3}) - y_i)}},\\ j \\in \\{1,2,3\\}$$\n",
    "Здесь $\\eta$ - параметр, шаг градиентного спуска."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стохастический градиентный спуск\n",
    "Проблема градиентного спуска, описанного выше, в том, что на больших выборках считать на каждом шаге градиент по всем имеющимся данным может быть очень вычислительно сложно. \n",
    "В стохастическом варианте градиентного спуска поправки для весов вычисляются только с учетом одного случайно взятого объекта обучающей выборки:\n",
    "$$\\Large w_0 \\leftarrow w_0 - \\frac{2\\eta}{\\ell} {((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)}$$\n",
    "$$\\Large w_j \\leftarrow w_j - \\frac{2\\eta}{\\ell} {x_{kj}((w_0 + w_1x_{k1} + w_2x_{k2} +  w_3x_{k3}) - y_k)},\\ j \\in \\{1,2,3\\},$$\n",
    "где $k$ - случайный индекс, $k \\in \\{1, \\ldots, \\ell\\}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Нормальное уравнение \n",
    "Нахождение вектора оптимальных весов $w$ может быть сделано и аналитически.\n",
    "Мы хотим найти такой вектор весов $w$, чтобы вектор $y$, приближающий целевой признак, получался умножением матрицы $X$ (состоящей из всех признаков объектов обучающей выборки, кроме целевого) на вектор весов $w$. То есть, чтобы выполнялось матричное уравнение:\n",
    "$$\\Large y = Xw$$\n",
    "Домножением слева на $X^T$ получаем:\n",
    "$$\\Large X^Ty = X^TXw$$\n",
    "Это хорошо, поскольку теперь матрица $X^TX$ - квадратная, и можно найти решение (вектор $w$) в виде:\n",
    "$$\\Large w = {(X^TX)}^{-1}X^Ty$$\n",
    "Матрица ${(X^TX)}^{-1}X^T$ - [*псевдообратная*](https://ru.wikipedia.org/wiki/Псевдообратная_матрица) для матрицы $X$. В NumPy такую матрицу можно вычислить с помощью функции [numpy.linalg.pinv](http://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.pinv.html).\n",
    "\n",
    "Однако, нахождение псевдообратной матрицы - операция вычислительно сложная и нестабильная в случае малого определителя матрицы $X$ (проблема мультиколлинеарности). \n",
    "На практике лучше находить вектор весов $w$ решением матричного уравнения \n",
    "$$\\Large X^TXw = X^Ty$$Это может быть сделано с помощью функции [numpy.linalg.solve](http://docs.scipy.org/doc/numpy-1.10.1/reference/generated/numpy.linalg.solve.html).\n",
    "\n",
    "Но все же на практике для больших матриц $X$ быстрее работает градиентный спуск, особенно его стохастическая версия."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инструкции по выполнению"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В начале напишем простую функцию для записи ответов в текстовый файл. Ответами будут числа, полученные в ходе решения этого задания, округленные до 3 знаков после запятой. Полученные файлы после выполнения задания надо отправить в форму на странице задания на Coursera.org."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_answer_to_file(answer, filename):\n",
    "    with open(filename, 'w') as f_out:\n",
    "        f_out.write(str(round(answer, 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Загрузите данные из файла *advertising.csv* в объект pandas DataFrame. [Источник данных](http://www-bcf.usc.edu/~gareth/ISL/data.html).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "adver_data = pd.read_csv('advertising.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Посмотрите на первые 5 записей и на статистику признаков в этом наборе данных.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adver_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Создайте массивы NumPy *X* из столбцов TV, Radio и Newspaper и *y* - из столбца Sales. Используйте атрибут *values* объекта pandas DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array(adver_data[['TV','Radio','Newspaper']])\n",
    "y = np.array(adver_data['Sales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Отмасштабируйте столбцы матрицы *X*, вычтя из каждого значения среднее по соответствующему столбцу и поделив результат на стандартное отклонение. Для определенности, используйте методы mean и std векторов NumPy (реализация std в Pandas может отличаться). Обратите внимание, что в numpy вызов функции .mean() без параметров возвращает среднее по всем элементам массива, а не по столбцам, как в pandas. Чтобы произвести вычисление по столбцам, необходимо указать параметр axis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "means, stds = (np.mean(X,axis=0),np.std(X,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Добавьте к матрице *X* столбец из единиц, используя методы *hstack*, *ones* и *reshape* библиотеки NumPy. Вектор из единиц нужен для того, чтобы не обрабатывать отдельно коэффициент $w_0$ линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.00000000e+00   9.69852266e-01   9.81522472e-01   1.77894547e+00]\n",
      " [  1.00000000e+00  -1.19737623e+00   1.08280781e+00   6.69578760e-01]\n",
      " [  1.00000000e+00  -1.51615499e+00   1.52846331e+00   1.78354865e+00]\n",
      " [  1.00000000e+00   5.20496822e-02   1.21785493e+00   1.28640506e+00]\n",
      " [  1.00000000e+00   3.94182198e-01  -8.41613655e-01   1.28180188e+00]\n",
      " [  1.00000000e+00  -1.61540845e+00   1.73103399e+00   2.04592999e+00]\n",
      " [  1.00000000e+00  -1.04557682e+00   6.43904671e-01  -3.24708413e-01]\n",
      " [  1.00000000e+00  -3.13436589e-01  -2.47406325e-01  -8.72486994e-01]\n",
      " [  1.00000000e+00  -1.61657614e+00  -1.42906863e+00  -1.36042422e+00]\n",
      " [  1.00000000e+00   6.16042873e-01  -1.39530685e+00  -4.30581584e-01]\n",
      " [  1.00000000e+00  -9.45155670e-01  -1.17923146e+00  -2.92486143e-01]\n",
      " [  1.00000000e+00   7.90028350e-01   4.96973404e-02  -1.22232878e+00]\n",
      " [  1.00000000e+00  -1.43908760e+00   7.99208859e-01   1.62704048e+00]\n",
      " [  1.00000000e+00  -5.78501712e-01  -1.05768905e+00  -1.07502697e+00]\n",
      " [  1.00000000e+00   6.66253447e-01   6.50657027e-01   7.11007392e-01]\n",
      " [  1.00000000e+00   5.64664612e-01   1.65000572e+00   1.02862691e+00]\n",
      " [  1.00000000e+00  -9.25304978e-01   9.00494200e-01   3.84117072e+00]\n",
      " [  1.00000000e+00   1.56887609e+00   1.10306488e+00   1.16211917e+00]\n",
      " [  1.00000000e+00  -9.08957349e-01  -1.86635121e-01  -5.64073843e-01]\n",
      " [  1.00000000e+00   3.00679600e-03   4.29449843e-02  -5.27248393e-01]\n",
      " [  1.00000000e+00   8.33232798e-01   2.99534513e-01   1.05164281e+00]\n",
      " [  1.00000000e+00   1.05509347e+00  -1.22649795e+00  -3.24708413e-01]\n",
      " [  1.00000000e+00  -1.56286250e+00  -4.97243498e-01   8.76721921e-01]\n",
      " [  1.00000000e+00   9.48833887e-01  -4.29719938e-01  -2.00422516e-01]\n",
      " [  1.00000000e+00  -9.89527805e-01  -7.20071247e-01  -5.64073843e-01]\n",
      " [  1.00000000e+00   1.35285385e+00  -1.33453565e+00  -5.08835667e-01]\n",
      " [  1.00000000e+00  -4.83714657e-02   4.07572210e-01  -8.26455181e-01]\n",
      " [  1.00000000e+00   1.08662104e+00  -4.43224650e-01  -3.52327501e-01]\n",
      " [  1.00000000e+00   1.18820988e+00   2.59020377e-01  -3.52327501e-01]\n",
      " [  1.00000000e+00  -8.92609721e-01  -4.90491142e-01   4.71641962e-01]\n",
      " [  1.00000000e+00   1.70316018e+00   3.40048650e-01   5.82118314e-01]\n",
      " [  1.00000000e+00  -3.98677796e-01  -3.95958157e-01   3.70371972e-01]\n",
      " [  1.00000000e+00  -5.82004775e-01  -1.46958277e+00  -2.55016247e-02]\n",
      " [  1.00000000e+00   1.38438142e+00  -2.20396901e-01  -1.39264649e+00]\n",
      " [  1.00000000e+00  -5.99520091e-01  -1.47633512e+00  -1.06582061e+00]\n",
      " [  1.00000000e+00   1.67747105e+00  -1.29402151e+00  -1.01518562e+00]\n",
      " [  1.00000000e+00   1.39956136e+00   1.38666383e+00  -1.17629696e+00]\n",
      " [  1.00000000e+00  -8.44734522e-01   1.76479577e+00   6.97197848e-01]\n",
      " [  1.00000000e+00  -1.21372386e+00   2.32010953e-01   2.09260624e-01]\n",
      " [  1.00000000e+00   9.45330823e-01   9.74770116e-01   6.65620024e-02]\n",
      " [  1.00000000e+00   6.47570443e-01  -6.50927121e-02   4.81492770e-02]\n",
      " [  1.00000000e+00   3.49810063e-01   6.84418807e-01   3.74975153e-01]\n",
      " [  1.00000000e+00   1.71133400e+00   2.99534513e-01  -1.32359877e+00]\n",
      " [  1.00000000e+00   6.98948705e-01  -1.00367020e+00  -1.91216154e-01]\n",
      " [  1.00000000e+00  -1.42390765e+00   1.64487393e-01   5.86721496e-01]\n",
      " [  1.00000000e+00   3.27623995e-01  -5.15880000e-02   4.35460956e-02]\n",
      " [  1.00000000e+00  -6.69581357e-01  -9.02384859e-01   2.36879713e-01]\n",
      " [  1.00000000e+00   1.08428567e+00   1.23135965e+00  -5.54867481e-01]\n",
      " [  1.00000000e+00   9.35989321e-01  -5.03995854e-01   8.90531465e-01]\n",
      " [  1.00000000e+00  -9.35814168e-01  -7.80842451e-01   2.87514708e-01]\n",
      " [  1.00000000e+00   6.16042873e-01  -1.36154507e+00   1.86244718e-01]\n",
      " [  1.00000000e+00  -5.44638766e-01  -9.22641928e-01  -1.24074150e+00]\n",
      " [  1.00000000e+00   8.09879042e-01   1.24486436e+00   4.16403786e-01]\n",
      " [  1.00000000e+00   4.15200577e-01   1.54872038e+00   1.29561142e+00]\n",
      " [  1.00000000e+00   1.35051848e+00   3.73810430e-01  -6.74550196e-01]\n",
      " [  1.00000000e+00   6.05533683e-01   1.76479577e+00   1.35545278e+00]\n",
      " [  1.00000000e+00  -1.63175608e+00   3.26543937e-01   4.99261050e-01]\n",
      " [  1.00000000e+00  -1.26606546e-01  -2.74415749e-01  -6.42327927e-01]\n",
      " [  1.00000000e+00   7.44488528e-01   1.77830048e+00   3.28943340e-01]\n",
      " [  1.00000000e+00   7.43320840e-01   4.21076922e-01  -9.78360166e-01]\n",
      " [  1.00000000e+00  -1.09228433e+00  -1.43582099e+00  -4.21375221e-01]\n",
      " [  1.00000000e+00   1.33417085e+00   1.31238792e+00   1.11148417e+00]\n",
      " [  1.00000000e+00   1.07727954e+00  -5.24252922e-01  -1.49787521e-01]\n",
      " [  1.00000000e+00  -5.17781948e-01   4.27829278e-01  -1.01978880e+00]\n",
      " [  1.00000000e+00  -1.86158622e-01   1.31914027e+00  -7.61366196e-02]\n",
      " [  1.00000000e+00  -9.11292725e-01  -9.42898996e-01  -1.36502740e+00]\n",
      " [  1.00000000e+00  -1.34917564e+00   9.02114765e-02  -1.30518604e+00]\n",
      " [  1.00000000e+00  -9.04082253e-02  -5.91776482e-01  -9.36931533e-01]\n",
      " [  1.00000000e+00   1.05509347e+00   2.86029801e-01  -9.00106083e-01]\n",
      " [  1.00000000e+00   8.14549794e-01   1.39341619e+00  -1.54390703e-01]\n",
      " [  1.00000000e+00   6.07869059e-01   4.95352838e-01   3.74975153e-01]\n",
      " [  1.00000000e+00  -4.34876116e-01  -6.05281194e-01   5.27524584e-02]\n",
      " [  1.00000000e+00  -1.40405696e+00   6.57409383e-01  -5.18042030e-01]\n",
      " [  1.00000000e+00  -2.06009314e-01  -1.18598381e+00   3.43397329e-02]\n",
      " [  1.00000000e+00   7.74848409e-01   9.02114765e-02  -8.03439274e-01]\n",
      " [  1.00000000e+00  -1.51965805e+00   1.37991148e+00   2.70878810e+00]\n",
      " [  1.00000000e+00  -1.39588315e+00  -1.46283041e+00  -4.53597491e-01]\n",
      " [  1.00000000e+00  -3.09933525e-01   3.53553362e-01  -7.52804279e-01]\n",
      " [  1.00000000e+00  -1.65394214e+00   4.48086346e-01  -9.73756984e-01]\n",
      " [  1.00000000e+00  -3.62479475e-01  -1.05093669e+00  -3.43121138e-01]\n",
      " [  1.00000000e+00  -8.24883830e-01   2.32010953e-01  -3.79946589e-01]\n",
      " [  1.00000000e+00   1.08311798e+00  -1.29402151e+00   2.92117889e-01]\n",
      " [  1.00000000e+00  -8.37728396e-01  -2.00139833e-01   8.95779092e-02]\n",
      " [  1.00000000e+00  -9.18298852e-01   1.43393033e+00   2.32276531e-01]\n",
      " [  1.00000000e+00   7.76016097e-01   1.33264499e+00   1.49419267e-01]\n",
      " [  1.00000000e+00   5.38975481e-01  -3.28434597e-01   1.61783412e+00]\n",
      " [  1.00000000e+00  -8.26051518e-01   2.86029801e-01  -6.69947015e-01]\n",
      " [  1.00000000e+00  -4.24366926e-01   1.17058844e+00   1.50275459e+00]\n",
      " [  1.00000000e+00  -6.85928986e-01   1.50982681e-01   1.97227908e+00]\n",
      " [  1.00000000e+00  -4.34876116e-01   1.65675807e+00   9.59579186e-01]\n",
      " [  1.00000000e+00  -1.48792614e-01  -1.24000266e+00  -9.78360166e-01]\n",
      " [  1.00000000e+00  -1.38303858e+00  -1.46958277e+00   1.12593816e-01]\n",
      " [  1.00000000e+00   8.25058983e-01   6.91171163e-01   1.30942097e+00]\n",
      " [  1.00000000e+00   1.21273132e+00   8.93741844e-01   1.92164409e+00]\n",
      " [  1.00000000e+00  -4.62900623e-01  -6.25538262e-01  -9.04709264e-01]\n",
      " [  1.00000000e+00   1.89836839e-01   5.62876398e-01   1.02862691e+00]\n",
      " [  1.00000000e+00   5.90353742e-01  -1.33453565e+00  -1.13486833e+00]\n",
      " [  1.00000000e+00   4.42057396e-01  -1.52873340e-01  -3.93756133e-01]\n",
      " [  1.00000000e+00   1.66579418e+00   1.28537849e+00   9.50372823e-01]\n",
      " [  1.00000000e+00  -1.38283424e-01   1.24486436e+00   7.06404211e-01]\n",
      " [  1.00000000e+00   8.79940308e-01  -1.28051680e+00   8.85928284e-01]\n",
      " [  1.00000000e+00   1.74402926e+00   8.80237132e-01   3.23815396e+00]\n",
      " [  1.00000000e+00   1.55486384e+00  -8.88880147e-01  -4.21375221e-01]\n",
      " [  1.00000000e+00   4.77088029e-01  -4.09462869e-01  -5.82486569e-01]\n",
      " [  1.00000000e+00   1.06443498e+00   7.45190011e-01  -1.16248742e+00]\n",
      " [  1.00000000e+00  -1.06755854e-01   1.56222509e+00   1.30942097e+00]\n",
      " [  1.00000000e+00  -1.42507534e+00  -8.28108943e-01  -3.93111688e-02]\n",
      " [  1.00000000e+00  -6.61407543e-01  -1.55061104e+00  -3.38517957e-01]\n",
      " [  1.00000000e+00  -1.56403019e+00  -1.54385868e+00  -2.28041604e-01]\n",
      " [  1.00000000e+00   1.26527727e+00   2.45515665e-01  -1.15328106e+00]\n",
      " [  1.00000000e+00   9.19641692e-01  -1.01717491e+00   1.19434143e+00]\n",
      " [  1.00000000e+00   1.10530405e+00   9.95027184e-01  -3.38517957e-01]\n",
      " [  1.00000000e+00   3.34630122e-01  -5.31005278e-01  -1.29597968e+00]\n",
      " [  1.00000000e+00   7.30476274e-01  -1.79882765e-01  -9.13915627e-01]\n",
      " [  1.00000000e+00  -8.03865450e-01   1.58923451e+00   1.81641536e-01]\n",
      " [  1.00000000e+00  -8.40063771e-01   7.92456503e-01   1.01942054e+00]\n",
      " [  1.00000000e+00  -9.15759131e-02  -6.05281194e-01  -2.28041604e-01]\n",
      " [  1.00000000e+00  -8.24883830e-01  -1.51684926e+00  -7.25185191e-01]\n",
      " [  1.00000000e+00  -2.49213762e-01   9.20751268e-01   2.23926360e+00]\n",
      " [  1.00000000e+00  -1.49046586e+00  -4.90491142e-01  -3.79946589e-01]\n",
      " [  1.00000000e+00  -6.70544700e-02   2.38763309e-01   7.20213755e-01]\n",
      " [  1.00000000e+00  -1.49747198e+00  -1.05606848e-01   9.13547372e-01]\n",
      " [  1.00000000e+00   8.98623313e-01  -1.40881156e+00  -6.88359740e-01]\n",
      " [  1.00000000e+00  -2.79573643e-01   7.65447079e-01  -8.35661544e-01]\n",
      " [  1.00000000e+00   9.62846140e-01   6.10142891e-01   2.00910454e+00]\n",
      " [  1.00000000e+00  -6.98773552e-01  -7.74090095e-01  -2.14232060e-01]\n",
      " [  1.00000000e+00  -1.62591764e+00   1.05579839e+00   9.22753735e-01]\n",
      " [  1.00000000e+00  -7.80511695e-01  -1.57086811e+00  -9.82963347e-01]\n",
      " [  1.00000000e+00   8.55418865e-01   1.73778635e+00  -1.25915423e+00]\n",
      " [  1.00000000e+00  -1.02105537e+00  -7.60585383e-01   5.77515133e-01]\n",
      " [  1.00000000e+00  -1.70882347e+00   1.10306488e+00  -1.00597925e+00]\n",
      " [  1.00000000e+00   1.37971067e+00  -1.37504978e+00   5.72911952e-01]\n",
      " [  1.00000000e+00  -1.61891151e+00   2.65772733e-01  -1.30978922e+00]\n",
      " [  1.00000000e+00   8.49580427e-01   6.91171163e-01   6.69578760e-01]\n",
      " [  1.00000000e+00  -1.28612050e+00   1.03554132e+00   1.61323094e+00]\n",
      " [  1.00000000e+00  -1.15300409e+00   1.60273923e+00  -1.01518562e+00]\n",
      " [  1.00000000e+00  -1.41806922e+00   1.06255074e+00  -9.78360166e-01]\n",
      " [  1.00000000e+00   1.47896413e+00   3.80562786e-01   1.34164324e+00]\n",
      " [  1.00000000e+00  -1.21489154e+00   1.77992105e-01  -4.62803854e-01]\n",
      " [  1.00000000e+00   4.42057396e-01   1.39341619e+00  -1.32820195e+00]\n",
      " [  1.00000000e+00  -8.59914463e-01  -4.22967582e-01  -8.12645637e-01]\n",
      " [  1.00000000e+00   5.44813920e-01   8.19465927e-01   2.07354907e+00]\n",
      " [  1.00000000e+00   8.57754241e-01   6.70914095e-01   3.38149702e-01]\n",
      " [  1.00000000e+00  -4.95595880e-01  -1.18598381e+00   1.77038355e-01]\n",
      " [  1.00000000e+00  -5.93681653e-01  -5.71519414e-01   3.84181516e-01]\n",
      " [  1.00000000e+00  -7.87313476e-02  -1.44257334e+00  -9.92169710e-01]\n",
      " [  1.00000000e+00   1.08662104e+00  -1.07794612e+00  -1.00597925e+00]\n",
      " [  1.00000000e+00   1.12281936e+00   1.73778635e+00   6.32753309e-01]\n",
      " [  1.00000000e+00  -1.27327593e+00   1.15033137e+00  -8.58677450e-01]\n",
      " [  1.00000000e+00  -1.19504085e+00   1.71239749e-01  -4.58200672e-01]\n",
      " [  1.00000000e+00   1.56070228e+00  -6.32290618e-01   2.96721070e-01]\n",
      " [  1.00000000e+00  -3.04095087e-01  -1.00367020e+00   8.35293289e-01]\n",
      " [  1.00000000e+00   5.90353742e-01   2.43084817e-03  -7.52804279e-01]\n",
      " [  1.00000000e+00   2.83251860e-01   1.10981724e+00   3.28943340e-01]\n",
      " [  1.00000000e+00   4.75920341e-01  -1.46120984e-01  -9.69153803e-01]\n",
      " [  1.00000000e+00  -1.66912209e+00  -7.87594807e-01  -1.14407469e+00]\n",
      " [  1.00000000e+00  -6.20538471e-01   1.36640677e+00   9.18150553e-01]\n",
      " [  1.00000000e+00   3.21989902e-02  -1.48308748e+00  -2.87882962e-01]\n",
      " [  1.00000000e+00  -1.58037782e+00   9.20751268e-01   6.74181942e-01]\n",
      " [  1.00000000e+00  -1.79152496e-01  -3.28434597e-01   1.86244718e-01]\n",
      " [  1.00000000e+00   2.97264113e-01  -3.48691665e-01   6.72064478e-03]\n",
      " [  1.00000000e+00  -7.16288868e-01   8.46475352e-01   8.62912377e-01]\n",
      " [  1.00000000e+00   4.82926468e-01  -3.48691665e-01  -2.28041604e-01]\n",
      " [  1.00000000e+00   1.92172214e-01   9.13998912e-01  -1.06582061e+00]\n",
      " [  1.00000000e+00  -3.48467222e-01  -5.78271770e-01  -1.15788424e+00]\n",
      " [  1.00000000e+00   1.02123053e+00  -1.34128800e+00   2.49704176e+00]\n",
      " [  1.00000000e+00  -1.50798117e+00   9.68017760e-01  -4.12168859e-01]\n",
      " [  1.00000000e+00   6.97781017e-01  -1.21974559e+00  -5.13438849e-01]\n",
      " [  1.00000000e+00   7.98202165e-01   2.26879163e-02   1.24497643e+00]\n",
      " [  1.00000000e+00   1.60273904e+00  -8.55118367e-01  -1.11185242e+00]\n",
      " [  1.00000000e+00  -1.13315340e+00  -7.87594807e-01  -5.59470662e-01]\n",
      " [  1.00000000e+00   2.03849092e-01  -1.59625696e-01   7.75451931e-01]\n",
      " [  1.00000000e+00  -1.48813048e+00  -2.13644545e-01  -6.23915201e-01]\n",
      " [  1.00000000e+00   2.49388915e-01  -1.09145083e+00  -8.17248818e-01]\n",
      " [  1.00000000e+00   8.79940308e-01  -1.34128800e+00  -8.03439274e-01]\n",
      " [  1.00000000e+00   1.51633014e+00   1.73103399e+00   5.17673775e-01]\n",
      " [  1.00000000e+00   1.18353913e+00   4.68343414e-01  -4.72010216e-01]\n",
      " [  1.00000000e+00   2.70407294e-01  -1.04418434e+00   2.13863806e-01]\n",
      " [  1.00000000e+00   1.51399477e+00  -1.41556392e+00  -3.15502050e-01]\n",
      " [  1.00000000e+00   2.16693657e-01  -8.95632503e-01  -5.96296113e-01]\n",
      " [  1.00000000e+00   1.11601758e-01  -1.39530685e+00  -1.02439198e+00]\n",
      " [  1.00000000e+00   8.34400486e-01  -1.20624088e+00  -1.45184340e-01]\n",
      " [  1.00000000e+00  -1.06075676e+00  -1.18598381e+00  -3.93111688e-02]\n",
      " [  1.00000000e+00   1.64127273e+00   1.33264499e+00   1.89862818e+00]\n",
      " [  1.00000000e+00   1.24659427e+00  -1.32616272e-01  -2.55016247e-02]\n",
      " [  1.00000000e+00   6.76762637e-01   1.47444446e+00  -5.04232486e-01]\n",
      " [  1.00000000e+00  -8.80728498e-02  -1.42906863e+00  -1.82009791e-01]\n",
      " [  1.00000000e+00   5.14454038e-01   3.67058074e-01  -5.68677025e-01]\n",
      " [  1.00000000e+00   1.62258973e+00  -6.32290618e-01  -1.23613832e+00]\n",
      " [  1.00000000e+00  -1.49863967e+00  -7.53833027e-01  -3.29311594e-01]\n",
      " [  1.00000000e+00  -1.25576062e+00   1.20435022e+00  -1.13947151e+00]\n",
      " [  1.00000000e+00  -8.35393020e-01  -8.41613655e-01  -1.13026515e+00]\n",
      " [  1.00000000e+00  -1.51615499e+00  -1.29402151e+00   4.81492770e-02]\n",
      " [  1.00000000e+00   2.30705910e-01   1.26512143e+00  -1.24074150e+00]\n",
      " [  1.00000000e+00   3.10313024e-02   8.32970639e-01  -1.13026515e+00]\n",
      " [  1.00000000e+00  -1.27094056e+00  -1.32103093e+00  -7.71217005e-01]\n",
      " [  1.00000000e+00  -6.17035408e-01  -1.24000266e+00  -1.03359834e+00]\n",
      " [  1.00000000e+00   3.49810063e-01  -9.42898996e-01  -1.11185242e+00]\n",
      " [  1.00000000e+00   1.59456522e+00   1.26512143e+00   1.64085003e+00]\n",
      " [  1.00000000e+00   9.93206022e-01  -9.90165488e-01  -1.00597925e+00]]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(adver_data[['TV','Radio','Newspaper']])\n",
    "X = (X - means)/stds\n",
    "X = np.hstack((np.ones((len(X),1)), X))\n",
    "print X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Реализуйте функцию *mserror* - среднеквадратичную ошибку прогноза. Она принимает два аргумента - объекты Series *y* (значения целевого признака) и *y\\_pred* (предсказанные значения). Не используйте в этой функции циклы - тогда она будет вычислительно неэффективной.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mserror(y, y_pred):\n",
    "    return np.mean((y-y_pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales, если всегда предсказывать медианное значение Sales по исходной выборке? Запишите ответ в файл '1.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.346\n"
     ]
    }
   ],
   "source": [
    "y = adver_data['Sales']\n",
    "y_pred = np.median(y)\n",
    "answer1 = np.round(mserror(y,y_pred),3) \n",
    "print(answer1)\n",
    "write_answer_to_file(answer1, '1.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Реализуйте функцию *normal_equation*, которая по заданным матрицам (массивам NumPy) *X* и *y* вычисляет вектор весов $w$ согласно нормальному уравнению линейной регрессии.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normal_equation(X, y):\n",
    "    x_t = np.transpose(X)\n",
    "    inv = np.linalg.inv(np.dot(x_t,X))\n",
    "    inv_x = np.dot(inv,x_t)\n",
    "    return np.dot(inv_x,y) # Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 4)\n",
      "[ 14.0225       3.91925365   2.79206274  -0.02253861]\n"
     ]
    }
   ],
   "source": [
    "print X.shape\n",
    "norm_eq_weights = normal_equation(X, y)\n",
    "\n",
    "print(norm_eq_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какие продажи предсказываются линейной моделью с весами, найденными с помощью нормального уравнения, в случае средних инвестиций в рекламу по ТВ, радио и в газетах? (то есть при нулевых значениях масштабированных признаков TV, Radio и Newspaper). Запишите ответ в файл '2.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.0225\n"
     ]
    }
   ],
   "source": [
    "answer2 = sum(np.array([1,0,0,0]*norm_eq_weights))\n",
    "print(answer2)\n",
    "write_answer_to_file(answer2, '2.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Напишите функцию *linear_prediction*, которая принимает на вход матрицу *X* и вектор весов линейной модели *w*, а возвращает вектор прогнозов в виде линейной комбинации столбцов матрицы *X* с весами *w*.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_prediction(X, w):\n",
    "    return np.dot(X,w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью нормального уравнения? Запишите ответ в файл '3.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78412631451\n"
     ]
    }
   ],
   "source": [
    "answer3 = mserror(y,linear_prediction(X,norm_eq_weights))\n",
    "print(answer3)\n",
    "write_answer_to_file(answer3, '3.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Напишите функцию *stochastic_gradient_step*, реализующую шаг стохастического градиентного спуска для линейной регрессии. Функция должна принимать матрицу *X*, вектора *y* и *w*, число *train_ind* - индекс объекта обучающей выборки (строки матрицы *X*), по которому считается изменение весов, а также число *$\\eta$* (eta) - шаг градиентного спуска (по умолчанию *eta*=0.01). Результатом будет вектор обновленных весов. Наша реализация функции будет явно написана для данных с 3 признаками, но несложно модифицировать для любого числа признаков, можете это сделать.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_step(X, y, w, train_ind, eta=0.01):\n",
    "    grads = []\n",
    "    l = len(w)\n",
    "    x = np.array(X[train_ind])\n",
    "    for i in range(l):\n",
    "        grads.append(2.*x[i]*(sum(x*w) - y[train_ind]))\n",
    "    return  w - eta * np.array(grads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Напишите функцию *stochastic_gradient_descent*, реализующую стохастический градиентный спуск для линейной регрессии. Функция принимает на вход следующие аргументы:**\n",
    "- X - матрица, соответствующая обучающей выборке\n",
    "- y - вектор значений целевого признака\n",
    "- w_init - вектор начальных весов модели\n",
    "- eta - шаг градиентного спуска (по умолчанию 0.01)\n",
    "- max_iter - максимальное число итераций градиентного спуска (по умолчанию 10000)\n",
    "- max_weight_dist - минимальное евклидово расстояние между векторами весов на соседних итерациях градиентного спуска,\n",
    "при котором алгоритм прекращает работу (по умолчанию 1e-8)\n",
    "- seed - число, используемое для воспроизводимости сгенерированных псевдослучайных чисел (по умолчанию 42)\n",
    "- verbose - флаг печати информации (например, для отладки, по умолчанию False)\n",
    "\n",
    "**На каждой итерации в вектор (список) должно записываться текущее значение среднеквадратичной ошибки. Функция должна возвращать вектор весов $w$, а также вектор (список) ошибок.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stochastic_gradient_descent(X, y, w_init, eta=1e-2, max_iter=1e4,\n",
    "                                min_weight_dist=1e-8, seed=42, verbose=False):\n",
    "    # Инициализируем расстояние между векторами весов на соседних\n",
    "    # итерациях большим числом. \n",
    "    weight_dist = np.inf\n",
    "    # Инициализируем вектор весов\n",
    "    w = w_init\n",
    "    # Сюда будем записывать ошибки на каждой итерации\n",
    "    errors = []\n",
    "    # Счетчик итераций\n",
    "    iter_num = 0\n",
    "    # Будем порождать псевдослучайные числа \n",
    "    # (номер объекта, который будет менять веса), а для воспроизводимости\n",
    "    # этой последовательности псевдослучайных чисел используем seed.\n",
    "    np.random.seed(seed)\n",
    "        \n",
    "    # Основной цикл\n",
    "    while weight_dist > min_weight_dist and iter_num < max_iter:\n",
    "        # порождаем псевдослучайный \n",
    "        # индекс объекта обучающей выборки\n",
    "        random_ind = np.random.randint(X.shape[0])\n",
    "        errors.append(mserror(y,linear_prediction(X,w)))\n",
    "        w_old = w\n",
    "        w = stochastic_gradient_step(X,y,w,random_ind)\n",
    "        weight_dist = abs(sum(w - w_old))\n",
    "        iter_num+=1\n",
    "        \n",
    "    return w, errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Запустите $10^5$ итераций стохастического градиентного спуска. Укажите вектор начальных весов *w_init*, состоящий из нулей. Оставьте параметры  *eta* и *seed* равными их значениям по умолчанию (*eta*=0.01, *seed*=42 - это важно для проверки ответов).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.19 s, sys: 35.3 ms, total: 5.22 s\n",
      "Wall time: 5.26 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y = np.array(adver_data['Sales'])\n",
    "stoch_grad_desc_weights, stoch_errors_by_iter = stochastic_gradient_descent(X,y,np.array([0,0,0,0]),max_iter=1e5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим, чему равна ошибка на первых 50 итерациях стохастического градиентного спуска. Видим, что ошибка не обязательно уменьшается на каждой итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x114de1590>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEPCAYAAABRHfM8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBUNERIqigiEiIkX5/2e6jRq9IuT8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114d6e310>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(400), stoch_errors_by_iter[:400])\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Теперь посмотрим на зависимость ошибки от номера итерации для $10^5$ итераций стохастического градиентного спуска. Видим, что алгоритм сходится.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x114ed2550>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZYAAAEPCAYAAABhkeIdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114ecb7d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "plot(range(len(stoch_errors_by_iter)), stoch_errors_by_iter)\n",
    "xlabel('Iteration number')\n",
    "ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на вектор весов, к которому сошелся метод.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 13.97836994,   3.87934503,   3.14134212,   0.18323907])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoch_grad_desc_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Посмотрим на среднеквадратичную ошибку на последней итерации.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "answer4 = min(stoch_errors_by_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какова среднеквадратичная ошибка прогноза значений Sales в виде линейной модели с весами, найденными с помощью градиентного спуска? Запишите ответ в файл '4.txt'.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.78442112537\n"
     ]
    }
   ],
   "source": [
    "print(answer4)\n",
    "write_answer_to_file(answer4, '4.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ответами к заданию будут текстовые файлы, полученные в ходе этого решения. Обратите внимание, что отправленные файлы не должны содержать пустую строку в конце. Данный нюанс является ограничением платформы Coursera. Мы работаем над исправлением этого ограничения.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
